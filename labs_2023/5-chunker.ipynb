{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5028d7bab0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100 #50\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_similarity(d1, d2):\n",
    "    return np.dot(d1, d2) / (np.sqrt(np.dot(d1, d1)) * np.sqrt(np.dot(d2, d2)))\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    distances = []\n",
    "    for word in embeddings:\n",
    "        distances.append((word, cosine_similarity(embeddings[target_word], embeddings[word])))\n",
    "    distances.sort(key=lambda x: x[1], reverse=True)\n",
    "    return list(map(lambda x: x[0], distances[0:count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            X.append([word[key_x].lower() for word in sentence])\n",
    "        else:\n",
    "            X.append([word[key_x] for word in sentence])\n",
    "        Y.append([word[key_y] for word in sentence])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "chunks = []\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words.append(word['form'].lower())\n",
    "        chunks.append(word['chunk'])\n",
    "words = sorted(list(set(words)))\n",
    "chunks = sorted(list(set(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(words + embedded_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = dict(enumerate(vocabulary_words, start=2))\n",
    "idx2chunk = dict(enumerate(chunks, start=1))\n",
    "word2idx = {v:k for k,v in idx2word.items()}\n",
    "chunk2idx = {v:k for k,v in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, \n",
    "                                                       freeze=False, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, \n",
    "                            batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train_padded, Y_train_padded, embeddings_dict, embedding_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:04<00:00, 60.51it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.59it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 64.85it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.48it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 63.75it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.67it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.36it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.93it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.51it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.57it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.46it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.01it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.58it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.91it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 67.05it/s]\n"
     ]
    }
   ],
   "source": [
    "model1.to(device)\n",
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)        \n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(X_train.shape[0],1024)):\n",
    "            train_accuracy += torch.sum(torch.argmax(model1(X_train[i:i+1024,:]), dim=-1) == Y_train[i:i+1024])\n",
    "    # history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.LongTensor(sentence_word_idxs).to(device))\n",
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8897e-09, 8.5528e-08, 5.4302e-07, 2.5869e-10, 7.4637e-07, 2.9800e-07,\n",
       "        9.9969e-01, 7.2301e-07, 1.4126e-09, 1.8492e-07, 4.7863e-08, 3.1908e-10,\n",
       "        7.8538e-10, 9.8438e-10, 3.9615e-09, 6.0516e-09, 1.4431e-06, 2.7522e-09,\n",
       "        7.1618e-09, 3.1320e-09, 2.0237e-08, 2.7840e-10, 3.0771e-04],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2072e-13, 4.7664e-10, 3.5222e-09, 7.4905e-13, 8.2765e-10, 9.5403e-09,\n",
       "        1.0000e+00, 9.4836e-10, 3.9878e-12, 4.5347e-09, 1.2401e-11, 1.8891e-13,\n",
       "        1.4451e-13, 1.7238e-13, 1.3286e-12, 2.0025e-11, 9.5634e-09, 1.7781e-12,\n",
       "        1.2139e-11, 2.6272e-12, 5.4331e-11, 9.5586e-15, 1.6024e-06],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(word, 1) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model1.state_dict(), 'model.pt')\n",
    "# torch.cuda.empty_cache()\n",
    "model1.load_state_dict(torch.load('model.pt'))\n",
    "model1.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-5.9060, -3.0051, -4.5336,  ..., -1.7516, -4.0506,  2.8424],\n",
      "        [-7.6035, -6.1469, -3.4187,  ..., -2.4619,  1.5797,  3.5747],\n",
      "        [-8.6454, -4.1716, -3.0668,  ..., -4.7475, -5.8113,  3.0542],\n",
      "        ...,\n",
      "        [-3.9918, -1.2863, -3.8770,  ..., -3.3009, -4.9518, -0.0736],\n",
      "        [-3.7830, -1.1167, -3.7869,  ..., -3.2287, -4.8372, -0.2314],\n",
      "        [-3.6266, -0.9919, -3.7375,  ..., -3.1679, -4.7525, -0.3272]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958233914973962"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
