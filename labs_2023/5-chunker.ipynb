{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f46284cbb10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100 #50\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_similarity(d1, d2):\n",
    "    return np.dot(d1, d2) / (np.sqrt(np.dot(d1, d1)) * np.sqrt(np.dot(d2, d2)))\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    distances = []\n",
    "    for word in embeddings:\n",
    "        distances.append((word, cosine_similarity(embeddings[target_word], embeddings[word])))\n",
    "    distances.sort(key=lambda x: x[1], reverse=True)\n",
    "    return list(map(lambda x: x[0], distances[0:count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            X.append([word[key_x].lower() for word in sentence])\n",
    "        else:\n",
    "            X.append([word[key_x] for word in sentence])\n",
    "        Y.append([word[key_y] for word in sentence])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "chunks = []\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words.append(word['form'].lower())\n",
    "        chunks.append(word['chunk'])\n",
    "words = sorted(list(set(words)))\n",
    "chunks = sorted(list(set(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(words + embedded_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = dict(enumerate(vocabulary_words, start=2))\n",
    "idx2chunk = dict(enumerate(chunks, start=1))\n",
    "word2idx = {v:k for k,v in idx2word.items()}\n",
    "chunk2idx = {v:k for k,v in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, \n",
    "                                                       freeze=False, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, \n",
    "                            batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:04<00:00, 58.30it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.97it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.99it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 67.30it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.49it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.59it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.61it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 64.74it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 64.10it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.35it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.39it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 66.29it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.01it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.75it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 65.24it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1.to(device)\n",
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)        \n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_train), 1024):\n",
    "            x = X_train[i:i+1024,:].to(device)\n",
    "            y = Y_train[i:i+1024].to(device)\n",
    "            train_accuracy += torch.sum(torch.mul(torch.argmax(model1(x), dim=-1) == y, y > 0))\n",
    "    # train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy.item()/torch.sum(Y_train > 0)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.LongTensor(sentence_word_idxs).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0404e-09, 4.2912e-07, 1.0706e-06, 1.0118e-09, 1.3854e-06, 2.9034e-07,\n",
       "        9.9947e-01, 6.5401e-07, 2.8692e-09, 3.6522e-07, 6.9777e-08, 9.1882e-10,\n",
       "        2.8824e-09, 1.9399e-09, 3.2497e-09, 2.6625e-08, 1.4327e-06, 3.3124e-09,\n",
       "        9.1185e-09, 3.4227e-09, 2.4427e-08, 4.1863e-10, 5.2007e-04],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(word, 1) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model1.state_dict(), 'model.pt')\n",
    "# torch.cuda.empty_cache()\n",
    "# model1.load_state_dict(torch.load('model.pt'))\n",
    "model1.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-5.8625, -2.4728, -4.2764,  ..., -1.7145, -3.8255,  2.3979],\n",
      "        [-7.4904, -4.9271, -2.3933,  ..., -2.1741,  1.7450,  3.2497],\n",
      "        [-8.4553, -2.9159, -2.4517,  ..., -4.2097, -5.4642,  2.9892],\n",
      "        ...,\n",
      "        [-4.0435, -1.2490, -3.7592,  ..., -3.3716, -4.2549, -0.3362],\n",
      "        [-3.8433, -1.1040, -3.6810,  ..., -3.2881, -4.1641, -0.4663],\n",
      "        [-3.6914, -0.9984, -3.6376,  ..., -3.2176, -4.0998, -0.5428]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962689966458237"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
