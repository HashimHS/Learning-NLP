{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faaf64cfa30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300 #50\n",
    "LSTM_HIDDEN_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_file = 'corpus/glove.6B.100d.txt'\n",
    "# embedding_file = 'corpus/glove.6B.300d.txt'\n",
    "embedding_file = 'corpus/glove.42B.300d.txt'\n",
    "# embedding_file = 'corpus/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 1917494'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1/2/2008',\n",
       " '1/2/2009',\n",
       " '1/2/2010',\n",
       " '1/2/2011',\n",
       " '1/2/2012',\n",
       " '1/2/2013',\n",
       " '1/2/3',\n",
       " '1/2/4',\n",
       " '1/2/5',\n",
       " '1/20']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73117 , -0.44407 ,  0.22863 ,  0.32582 , -0.069017,  0.29342 ,\n",
       "       -1.6415  , -0.23372 ,  0.11325 , -0.80541 ,  0.58405 ,  0.16712 ,\n",
       "       -0.89039 ,  0.37771 , -0.24962 ,  0.40288 , -0.10095 ,  0.064693,\n",
       "       -0.18085 ,  0.51575 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_similarity(d1, d2):\n",
    "    return np.dot(d1, d2) / (np.sqrt(np.dot(d1, d1)) * np.sqrt(np.dot(d2, d2)))\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    distances = []\n",
    "    for word in embeddings:\n",
    "        distances.append((word, cosine_similarity(embeddings[target_word], embeddings[word])))\n",
    "    distances.sort(key=lambda x: x[1], reverse=True)\n",
    "    return list(map(lambda x: x[0], distances[0:count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'europe',\n",
       " 'paris',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'spain',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'switzerland',\n",
       " 'luxembourg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'germany',\n",
       " 'estonia',\n",
       " 'stockholm',\n",
       " 'switzerland',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            X.append([word[key_x].lower() for word in sentence])\n",
    "        else:\n",
    "            X.append([word[key_x] for word in sentence])\n",
    "        Y.append([word[key_y] for word in sentence])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "chunks = []\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words.append(word['form'].lower())\n",
    "        chunks.append(word['chunk'])\n",
    "words = sorted(list(set(words)))\n",
    "chunks = sorted(list(set(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(words + embedded_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 1918351\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1913-17',\n",
       " '1913-1914',\n",
       " '1913-1914.',\n",
       " '1913-1915',\n",
       " '1913-1916',\n",
       " '1913-1917',\n",
       " '1913-1918',\n",
       " '1913-1919',\n",
       " '1913-1920',\n",
       " '1913-1921']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = dict(enumerate(vocabulary_words, start=2))\n",
    "idx2chunk = dict(enumerate(chunks, start=1))\n",
    "word2idx = {v:k for k,v in idx2word.items()}\n",
    "chunk2idx = {v:k for k,v in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!!!!!!', 7), ('!!!!!!!', 8), ('!!!!!!!!', 9), ('!!!!!!!!!', 10), ('!!!!!!!!!!', 11), ('!!!!!!!!!!!', 12), ('!!!!!!!!!!!!', 13), ('!!!!!!!!!!!!!', 14), ('!!!!!!!!!!!!!!', 15), ('!!!!!!!!!!!!!!!', 16), ('!!!!!!!!!!!!!!!!', 17), ('!!!!!!!!!!!!!!!!!', 18), ('!!!!!!!!!!!!!!!!!!', 19), ('!!!!!!!!!!!!!!!!!!!', 20), ('!!!!!!!!!!!!!!!!!!!!', 21), ('!!!!!!!!!!!!!!!!!!!!!', 22), ('!!!!!!!!!!!!!!!!!!!!!!', 23), ('!!!!!!!!!!!!!!!!!!!!!!!', 24), ('!!!!!!!!!!!!!!!!!!!!!!!!', 25), ('!!!!!!!!!!!!!!!!!!!!!!!!!', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918353, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"women's-rights\",\n",
       " 'woodmac',\n",
       " 'worker-compensation',\n",
       " 'working-girl',\n",
       " 'world-commerce',\n",
       " \"y'all\",\n",
       " 'year-before',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48524001,  0.039558  , -0.046947  , -0.056083  ,  0.84688002,\n",
       "       -0.095761  , -2.54049993,  0.39072999, -0.097248  ,  0.21303999])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00540048,  0.03457306, -0.01296801,  0.02510228,  0.00136785,\n",
       "       -0.03044032,  0.02263095,  0.02768296, -0.01973514, -0.02316351])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[704294, 1048244, 1731494, 1455426, 1071851, 1863829, 860507, 1751214, 1710857, 499157, 1609325, 785044, 1040147, 1762233, 883861, 900752, 1599158, 9515, 806382, 900752, 1521897, 1754377, 9515, 868101, 1751214, 1617369, 443770, 1687079, 1047894, 913392, 1099957, 494188, 530486, 7570, 1312851, 759020, 18920], [660791, 1357047, 1731494, 858787, 1325916, 1157370, 7570, 1529811, 698555, 1751214, 443770, 888765, 1274105, 1445191, 987527, 997085, 1751214, 1465292, 443770, 909720, 1048244, 1673095, 1382220, 1731494, 1403053, 1853609, 18920], [621821, 493351, 1514116, 1794062, 1695484, 900752, 1673095, 987527, 563339, 845992, 623644, 1731494, 660791, 7570, 868194, 1751214, 498575, 503890, 1319837, 1445191, 1237106, 1048244, 1007689, 1217626, 1020477, 1655621, 1154387, 1742442, 18920]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 660791, 1357047, 1731494,  858787, 1325916, 1157370,    7570, 1529811,\n",
       "         698555, 1751214,  443770,  888765, 1274105, 1445191,  987527,  997085,\n",
       "        1751214, 1465292,  443770,  909720, 1048244, 1673095, 1382220, 1731494,\n",
       "        1403053, 1853609,   18920,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, \n",
    "                                                       freeze=True, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=2, batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_HIDDEN_DIM = 24\n",
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(1918353, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 24, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=48, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 182.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.666, Train acc.: 0.794,  Epoch time = 1.621s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 252.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.610, Train acc.: 0.890,  Epoch time = 1.173s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 253.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.387, Train acc.: 0.914,  Epoch time = 1.173s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 260.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.298, Train acc.: 0.931,  Epoch time = 1.141s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 253.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.246, Train acc.: 0.940,  Epoch time = 1.164s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 256.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.216, Train acc.: 0.947,  Epoch time = 1.154s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 264.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.193, Train acc.: 0.952,  Epoch time = 1.130s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 237.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.176, Train acc.: 0.957,  Epoch time = 1.242s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 243.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.162, Train acc.: 0.960,  Epoch time = 1.212s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 264.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.150, Train acc.: 0.962,  Epoch time = 1.122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 246.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.139, Train acc.: 0.965,  Epoch time = 1.198s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 256.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.130, Train acc.: 0.968,  Epoch time = 1.154s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 250.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.121, Train acc.: 0.970,  Epoch time = 1.178s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 246.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.114, Train acc.: 0.974,  Epoch time = 1.198s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 251.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.107, Train acc.: 0.975,  Epoch time = 1.177s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 243.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.100, Train acc.: 0.977,  Epoch time = 1.211s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 240.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.094, Train acc.: 0.978,  Epoch time = 1.224s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 242.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 0.089, Train acc.: 0.978,  Epoch time = 1.215s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 245.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 0.084, Train acc.: 0.980,  Epoch time = 1.201s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 243.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 0.079, Train acc.: 0.982,  Epoch time = 1.207s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 244.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 0.075, Train acc.: 0.983,  Epoch time = 1.203s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 245.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 0.071, Train acc.: 0.984,  Epoch time = 1.201s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 248.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 0.068, Train acc.: 0.984,  Epoch time = 1.188s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 246.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 0.065, Train acc.: 0.986,  Epoch time = 1.197s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 252.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 0.061, Train acc.: 0.986,  Epoch time = 1.172s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 259.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 0.058, Train acc.: 0.985,  Epoch time = 1.139s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1.to(device)\n",
    "epochs = 25\n",
    "for epoch in range(epochs+1):\n",
    "    start_time = timer()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)        \n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_train), 256):\n",
    "            x = X_train[i:i+256,:].to(device)\n",
    "            y = Y_train[i:i+256].to(device)\n",
    "            train_accuracy += torch.sum(torch.mul(torch.argmax(model1(x), dim=-1) == y, y > 0))\n",
    "    # train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy.item()/torch.sum(Y_train > 0)]\n",
    "    history['loss'] += [train_loss/batch_cnt]\n",
    "    end_time = timer()\n",
    "    print((f\"Epoch: {epoch}, Train loss: {history['loss'][-1]:.3f}, Train acc.: {history['accuracy'][-1].item():.3f},  Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9848)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA31UlEQVR4nO3dfXxT5f3/8XcINAWhKbe9oYEiICI3hS83HTJQRrWg3w5EJooKIuIdClhxUJUi6KxTVJzAmGzAdIIoFrxDFCsVYUwm2J+6IeOm2IptAR0NFGghPb8/8m00tJSkpD1NeD0fj/MouXKdk0+Pwby5znWuWAzDMAQAAGCSBmYXAAAALmyEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQR4AJ12223KT4+vkb7PvbYY7JYLIEtyEfnUzeA+okwAtQzFovFpy07O9vsUgEgICx8Nw1Qv/ztb3/zevzyyy9rw4YNeuWVV7zar7rqKkVFRdX4dU6dOqXy8nLZbDa/9z19+rROnz6t8PDwGr9+Td12223Kzs7W/v376/y1AdSOhmYXAMDbLbfc4vX4H//4hzZs2FCp/UzHjx9XkyZNfH6dRo0a1ag+SWrYsKEaNuR/HwACg8s0QBC68sor1b17d23fvl2DBw9WkyZN9PDDD0uS3nrrLV177bWKjY2VzWZTx44d9fjjj8vlcnkd48y5F/v375fFYtG8efP00ksvqWPHjrLZbOrXr5/++c9/eu1b1ZwRi8Wi++67T2vXrlX37t1ls9nUrVs3rV+/vlL92dnZ6tu3r8LDw9WxY0f96U9/Oq95KCUlJXrwwQflcDhks9nUpUsXzZs3T2cO/G7YsEG//OUvFRkZqaZNm6pLly6e81bhxRdfVLdu3dSkSRM1b95cffv21YoVK7z6HDhwQLfffruioqI8v+fSpUsr1eXLsQAwMgIErR9++EHDhw/XjTfeqFtuucVzyWb58uVq2rSpUlNT1bRpU3388cdKT0+X0+nUM888c87jrlixQkePHtVdd90li8Wip59+WqNGjdK+ffvOOZqyefNmZWZm6t5771WzZs30hz/8Qddff73y8vLUsmVLSdIXX3yhYcOGKSYmRnPmzJHL5dLcuXPVunXrGp0HwzD061//Whs3btTEiRPVq1cvffDBB3rooYd04MABPf/885Kkf/3rX/rf//1f9ezZU3PnzpXNZtOePXu0ZcsWz7GWLFmiKVOmaPTo0Zo6dapOnjypL7/8Up999pnGjh0rSSoqKtIvfvELT/hq3bq13n//fU2cOFFOp1PTpk3z+VgA/o8BoF6bPHmyceZf1SuuuMKQZCxevLhS/+PHj1dqu+uuu4wmTZoYJ0+e9LSNHz/eaN++vedxbm6uIclo2bKl8eOPP3ra33rrLUOS8c4773jaZs+eXakmSUZYWJixZ88eT9v/+3//z5BkvPjii562lJQUo0mTJsaBAwc8bbt37zYaNmxY6ZhVObPutWvXGpKMJ554wqvf6NGjDYvF4qnn+eefNyQZhw4dOuuxR4wYYXTr1q3a1584caIRExNjHD582Kv9xhtvNOx2u+f8+3IsAG5cpgGClM1m04QJEyq1N27c2PPno0eP6vDhwxo0aJCOHz+ub7755pzHHTNmjJo3b+55PGjQIEnSvn37zrlvUlKSOnbs6Hncs2dPRUREePZ1uVz66KOPNHLkSMXGxnr6derUScOHDz/n8auybt06Wa1WTZkyxav9wQcflGEYev/99yVJkZGRktyXscrLy6s8VmRkpL777rtKl6UqGIahN998UykpKTIMQ4cPH/ZsycnJKi4u1o4dO3w6FoCfEEaAINW2bVuFhYVVav/Xv/6l6667Tna7XREREWrdurVn8mtxcfE5j9uuXTuvxxXB5L///a/f+1bsX7HvwYMHdeLECXXq1KlSv6rafPHtt98qNjZWzZo182rv2rWr53nJHbIGDhyoO+64Q1FRUbrxxhv1+uuvewWTGTNmqGnTpurfv786d+6syZMne13GOXTokI4cOaKXXnpJrVu39toqguHBgwd9OhaAnzBnBAhSPx8BqXDkyBFdccUVioiI0Ny5c9WxY0eFh4drx44dmjFjxllHBH7OarVW2W74sArA+exb2xo3bqxNmzZp48aNeu+997R+/XqtWrVKv/rVr/Thhx/KarWqa9eu2rVrl959912tX79eb775phYtWqT09HTNmTPHc/5uueUWjR8/vsrX6dmzpySd81gAfkIYAUJIdna2fvjhB2VmZmrw4MGe9tzcXBOr+kmbNm0UHh6uPXv2VHquqjZftG/fXh999JGOHj3qNTpScUmqffv2nrYGDRpo6NChGjp0qJ577jk9+eSTeuSRR7Rx40YlJSVJki666CKNGTNGY8aMUVlZmUaNGqXf/e53SktLU+vWrdWsWTO5XC5P/+pUdywz1mgB6isu0wAhpGJk4ucjEWVlZVq0aJFZJXmxWq1KSkrS2rVr9f3333va9+zZ45nb4a9rrrlGLpdLCxYs8Gp//vnnZbFYPHNRfvzxx0r79urVS5JUWloqyX2H0s+FhYXpsssuk2EYOnXqlKxWq66//nq9+eab+vrrrysd79ChQ54/n+tYAH7CyAgQQi6//HI1b95c48eP15QpU2SxWPTKK6/Ui8skFR577DF9+OGHGjhwoO655x5PkOjevbtycnL8Pl5KSoqGDBmiRx55RPv371dCQoI+/PBDvfXWW5o2bZpnQu3cuXO1adMmXXvttWrfvr0OHjyoRYsWKS4uTr/85S8lSVdffbWio6M1cOBARUVFaefOnVqwYIGuvfZaz6jLU089pY0bNyoxMVGTJk3SZZddph9//FE7duzQRx995Ak9vhwLgBthBAghLVu21LvvvqsHH3xQjz76qJo3b65bbrlFQ4cOVXJystnlSZL69Omj999/X9OnT9esWbPkcDg0d+5c7dy506e7fc7UoEEDvf3220pPT9eqVau0bNkyxcfH65lnntGDDz7o6ffrX/9a+/fv19KlS3X48GG1atVKV1xxhebMmSO73S5Juuuuu/Tqq6/queee07FjxxQXF6cpU6bo0Ucf9RwnKipK27Zt09y5c5WZmalFixapZcuW6tatm37/+997+vlyLABufDcNgHph5MiR+te//qXdu3ebXQqAOsacEQB17sSJE16Pd+/erXXr1unKK680pyAApmJkBECdi4mJ0W233aaLL75Y3377rf74xz+qtLRUX3zxhTp37mx2eQDqGHNGANS5YcOGaeXKlSosLJTNZtOAAQP05JNPEkSACxQjIwAAwFTMGQEAAKYijAAAAFMFxZyR8vJyff/992rWrJksFovZ5QAAAB8YhqGjR48qNjZWDRqcffwjKMLI999/L4fDYXYZAACgBvLz8xUXF3fW54MijFQsnZyfn6+IiAiTqwEAAL5wOp1yOBzn/AqEoAgjFZdmIiIiCCMAAASZc02xYAIrAAAwFWEEAACYijACAABMFRRzRgAA5jMMQ6dPn5bL5TK7FNQTVqtVDRs2PO9lNwgjAIBzKisrU0FBgY4fP252KahnmjRpopiYGIWFhdX4GIQRAEC1ysvLlZubK6vVqtjYWIWFhbEAJWQYhsrKynTo0CHl5uaqc+fO1S5sVh3CCACgWmVlZSovL5fD4VCTJk3MLgf1SOPGjdWoUSN9++23KisrU3h4eI2OwwRWAIBPavqvXoS2QLwvLtiREZdL+vRTqaBAiomRBg2SrFazqwIA4MJzQYaRzExp6lTpu+9+aouLk154QRo1yry6AAC4EF1wY26ZmdLo0d5BRJIOHHC3Z2aaUxcAhDqXS8rOllaudP8MxjuE4+PjNX/+fJ/7Z2dny2Kx6MiRI7VWkyQtX75ckZGRtfoatemCCiMul3tExDAqP1fRNm1acP4FAYD6LDNTio+XhgyRxo51/4yPr71/AFoslmq3xx57rEbH/ec//6k777zT5/6XX365CgoKZLfba/R6F4oL6jLNp59WHhH5OcOQ8vPd/a68ss7KAoCQVjEifeY/BCtGpFevDvwl8oKCAs+fV61apfT0dO3atcvT1rRpU8+fDcOQy+VSw4bn/khs3bq1X3WEhYUpOjrar30uRBfUyMjP3psB6QcAqJ5ZI9LR0dGezW63y2KxeB5/8803atasmd5//3316dNHNptNmzdv1t69ezVixAhFRUWpadOm6tevnz766COv4555mcZisejPf/6zrrvuOjVp0kSdO3fW22+/7Xn+zMs0FZdTPvjgA3Xt2lVNmzbVsGHDvMLT6dOnNWXKFEVGRqply5aaMWOGxo8fr5EjR/p1Dv74xz+qY8eOCgsLU5cuXfTKK694njMMQ4899pjatWsnm82m2NhYTZkyxfP8okWL1LlzZ4WHhysqKkqjR4/267X9dUGFkZiYwPYDAFTPnxHpujZz5kw99dRT2rlzp3r27Kljx47pmmuuUVZWlr744gsNGzZMKSkpysvLq/Y4c+bM0Q033KAvv/xS11xzjW6++Wb9+OOPZ+1//PhxzZs3T6+88oo2bdqkvLw8TZ8+3fP873//e7366qtatmyZtmzZIqfTqbVr1/r1u61Zs0ZTp07Vgw8+qK+//lp33XWXJkyYoI0bN0qS3nzzTT3//PP605/+pN27d2vt2rXq0aOHJOnzzz/XlClTNHfuXO3atUvr16/X4MGD/Xp9vxlBoLi42JBkFBcXn9dxTp82jLg4w7BYDMP9V8B7s1gMw+Fw9wMAuJ04ccL497//bZw4ccLvfVesqPr/t2duK1bUQuH/Z9myZYbdbvc83rhxoyHJWLt27Tn37datm/Hiiy96Hrdv3954/vnnPY8lGY8++qjn8bFjxwxJxvvvv+/1Wv/97389tUgy9uzZ49ln4cKFRlRUlOdxVFSU8cwzz3genz592mjXrp0xYsQIn3/Hyy+/3Jg0aZJXn9/85jfGNddcYxiGYTz77LPGJZdcYpSVlVU61ptvvmlEREQYTqfzrK/3c9W9P3z9/L6gRkasVvftu5J05krGFY/nz2e9EQAIlPo8It23b1+vx8eOHdP06dPVtWtXRUZGqmnTptq5c+c5R0Z69uzp+fNFF12kiIgIHTx48Kz9mzRpoo4dO3oex8TEePoXFxerqKhI/fv39zxvtVrVp08fv363nTt3auDAgV5tAwcO1M6dOyVJv/nNb3TixAldfPHFmjRpktasWaPTp09Lkq666iq1b99eF198sW699Va9+uqrtf6dRBdUGJHck6RWr5batvVuj4urnUlUAHAhGzTI/f/Xs32VjcUiORzufnXtoosu8no8ffp0rVmzRk8++aQ+/fRT5eTkqEePHiorK6v2OI0aNfJ6bLFYVF5e7ld/o6pJNbXI4XBo165dWrRokRo3bqx7771XgwcP1qlTp9SsWTPt2LFDK1euVExMjNLT05WQkFCrtydfcGFEcgeO/fuljRulFSvcP3NzCSIAEGjBNCK9ZcsW3XbbbbruuuvUo0cPRUdHa//+/XVag91uV1RUlP75z3962lwul3bs2OHXcbp27aotW7Z4tW3ZskWXXXaZ53Hjxo2VkpKiP/zhD8rOztbWrVv11VdfSZIaNmyopKQkPf300/ryyy+1f/9+ffzxx+fxm1Xvgrq19+esVm7fBYC6UDEiXdXK1/Pn159/CHbu3FmZmZlKSUmRxWLRrFmzqh3hqC3333+/MjIy1KlTJ1166aV68cUX9d///tevb0p+6KGHdMMNN6h3795KSkrSO++8o8zMTM/dQcuXL5fL5VJiYqKaNGmiv/3tb2rcuLHat2+vd999V/v27dPgwYPVvHlzrVu3TuXl5erSpUtt/coXbhgBANSdUaOkESPq93eCPffcc7r99tt1+eWXq1WrVpoxY4acTmed1zFjxgwVFhZq3LhxslqtuvPOO5WcnCyrHydr5MiReuGFFzRv3jxNnTpVHTp00LJly3Tl//0rPDIyUk899ZRSU1PlcrnUo0cPvfPOO2rZsqUiIyOVmZmpxx57TCdPnlTnzp21cuVKdevWrZZ+Y8li1PWFqhpwOp2y2+0qLi5WRESE2eUAwAXl5MmTys3NVYcOHWr8FfGoufLycnXt2lU33HCDHn/8cbPLqaS694evn9+MjAAAUI98++23+vDDD3XFFVeotLRUCxYsUG5ursaOHWt2abXG7wmsmzZtUkpKimJjY2WxWHxaiKW0tFSPPPKI2rdvL5vNpvj4eC1durQm9QIAENIaNGig5cuXq1+/fho4cKC++uorffTRR+ratavZpdUav0dGSkpKlJCQoNtvv12jfJx1dMMNN6ioqEh/+ctf1KlTJxUUFJgyKQgAgPrO4XBUuhMm1PkdRoYPH67hw4f73H/9+vX65JNPtG/fPrVo0UKSe21/AAAAqQ7WGXn77bfVt29fPf3002rbtq0uueQSTZ8+XSdOnDjrPqWlpXI6nV4bAMBcQXC/A0wQiPdFrU9g3bdvnzZv3qzw8HCtWbNGhw8f1r333qsffvhBy5Ytq3KfjIwMzZkzp7ZLAwD4oGLF0OPHj6tx48YmV4P6pmKp+DNXlvVHrYeR8vJyWSwWvfrqq7Lb7ZLc93KPHj3aswztmdLS0pSamup57HQ65XA4artUAEAVrFarIiMjPd+f0qRJE78W4EJoMgxDx48f18GDBxUZGenXOihnqvUwEhMTo7Zt23qCiOReptYwDH333Xfq3LlzpX1sNptsNlttlwYA8FF0dLQkVfsFcLgwRUZGet4fNVXrYWTgwIF64403dOzYMTVt2lSS9J///EcNGjRQXFxcbb88ACAALBaLYmJi1KZNG506dcrsclBPNGrU6LxGRCr4HUaOHTumPXv2eB7n5uYqJydHLVq0ULt27ZSWlqYDBw7o5ZdfliSNHTtWjz/+uCZMmKA5c+bo8OHDeuihh3T77bdz7REAgozVag3Ihw/wc37fTfP555+rd+/e6t27tyQpNTVVvXv3Vnp6uiSpoKBAeXl5nv5NmzbVhg0bdOTIEfXt21c333yz51sCAQAA+G4aAABQK3z9/K71dUYAAACqQxgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADCV32Fk06ZNSklJUWxsrCwWi9auXevzvlu2bFHDhg3Vq1cvf18WAACEKL/DSElJiRISErRw4UK/9jty5IjGjRunoUOH+vuSAAAghDX0d4fhw4dr+PDhfr/Q3XffrbFjx8pqtfo1mgIAAEJbncwZWbZsmfbt26fZs2f71L+0tFROp9NrAwAAoanWw8ju3bs1c+ZM/e1vf1PDhr4NxGRkZMhut3s2h8NRy1UCAACz1GoYcblcGjt2rObMmaNLLrnE5/3S0tJUXFzs2fLz82uxSgAAYCa/54z44+jRo/r888/1xRdf6L777pMklZeXyzAMNWzYUB9++KF+9atfVdrPZrPJZrPVZmkAAKCeqNUwEhERoa+++sqrbdGiRfr444+1evVqdejQoTZfHgAABAG/w8ixY8e0Z88ez+Pc3Fzl5OSoRYsWateundLS0nTgwAG9/PLLatCggbp37+61f5s2bRQeHl6pHQAAXJj8DiOff/65hgwZ4nmcmpoqSRo/fryWL1+ugoIC5eXlBa5CAAAQ0iyGYRhmF3EuTqdTdrtdxcXFioiIMLscAADgA18/v/luGgAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqfwOI5s2bVJKSopiY2NlsVi0du3aavtnZmbqqquuUuvWrRUREaEBAwbogw8+qGm9AAAgxPgdRkpKSpSQkKCFCxf61H/Tpk266qqrtG7dOm3fvl1DhgxRSkqKvvjiC7+LBQAAocdiGIZR450tFq1Zs0YjR470a79u3bppzJgxSk9P96m/0+mU3W5XcXGxIiIialApAACoa75+fjesw5okSeXl5Tp69KhatGhx1j6lpaUqLS31PHY6nXVRGgAAMEGdT2CdN2+ejh07phtuuOGsfTIyMmS32z2bw+GowwoBAEBdqtMwsmLFCs2ZM0evv/662rRpc9Z+aWlpKi4u9mz5+fl1WCUAAKhLdXaZ5rXXXtMdd9yhN954Q0lJSdX2tdlsstlsdVQZAAAwU52MjKxcuVITJkzQypUrde2119bFSwIAgCDh98jIsWPHtGfPHs/j3Nxc5eTkqEWLFmrXrp3S0tJ04MABvfzyy5Lcl2bGjx+vF154QYmJiSosLJQkNW7cWHa7PUC/BgAACFZ+j4x8/vnn6t27t3r37i1JSk1NVe/evT236RYUFCgvL8/T/6WXXtLp06c1efJkxcTEeLapU6cG6FcAAADB7LzWGakrrDMCAEDw8fXzm++mAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYyu8wsmnTJqWkpCg2NlYWi0Vr16495z7Z2dn6n//5H9lsNnXq1EnLly+vQakAACAU+R1GSkpKlJCQoIULF/rUPzc3V9dee62GDBminJwcTZs2TXfccYc++OADv4sFAAChp6G/OwwfPlzDhw/3uf/ixYvVoUMHPfvss5Kkrl27avPmzXr++eeVnJzs78sDAIAQU+tzRrZu3aqkpCSvtuTkZG3duvWs+5SWlsrpdHptAAAgNNV6GCksLFRUVJRXW1RUlJxOp06cOFHlPhkZGbLb7Z7N4XDUdpkAAMAk9fJumrS0NBUXF3u2/Px8s0sCAAC1xO85I/6Kjo5WUVGRV1tRUZEiIiLUuHHjKvex2Wyy2Wy1XRoAAKgHan1kZMCAAcrKyvJq27BhgwYMGFDbLw0AAIKA32Hk2LFjysnJUU5OjiT3rbs5OTnKy8uT5L7EMm7cOE//u+++W/v27dNvf/tbffPNN1q0aJFef/11PfDAA4H5DQAAQFDzO4x8/vnn6t27t3r37i1JSk1NVe/evZWeni5JKigo8AQTSerQoYPee+89bdiwQQkJCXr22Wf15z//mdt6AQCAJMliGIZhdhHn4nQ6ZbfbVVxcrIiICLPLAQAAPvD187te3k0DAAAuHIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABT1SiMLFy4UPHx8QoPD1diYqK2bdtWbf/58+erS5cuaty4sRwOhx544AGdPHmyRgUDAIDQ4ncYWbVqlVJTUzV79mzt2LFDCQkJSk5O1sGDB6vsv2LFCs2cOVOzZ8/Wzp079Ze//EWrVq3Sww8/fN7FAwCA4GcxDMPwZ4fExET169dPCxYskCSVl5fL4XDo/vvv18yZMyv1v++++7Rz505lZWV52h588EF99tln2rx5c5WvUVpaqtLSUs9jp9Mph8Oh4uJiRURE+FMuAAAwidPplN1uP+fnt18jI2VlZdq+fbuSkpJ+OkCDBkpKStLWrVur3Ofyyy/X9u3bPZdy9u3bp3Xr1umaa6456+tkZGTIbrd7NofD4U+ZAAAgiDT0p/Phw4flcrkUFRXl1R4VFaVvvvmmyn3Gjh2rw4cP65e//KUMw9Dp06d19913V3uZJi0tTampqZ7HFSMjAAAg9NT63TTZ2dl68skntWjRIu3YsUOZmZl677339Pjjj591H5vNpoiICK8NAACEJr9GRlq1aiWr1aqioiKv9qKiIkVHR1e5z6xZs3TrrbfqjjvukCT16NFDJSUluvPOO/XII4+oQQPuLgYA4ELmVxIICwtTnz59vCajlpeXKysrSwMGDKhyn+PHj1cKHFarVZLk59xZAAAQgvwaGZGk1NRUjR8/Xn379lX//v01f/58lZSUaMKECZKkcePGqW3btsrIyJAkpaSk6LnnnlPv3r2VmJioPXv2aNasWUpJSfGEEgAAcOHyO4yMGTNGhw4dUnp6ugoLC9WrVy+tX7/eM6k1Ly/PayTk0UcflcVi0aOPPqoDBw6odevWSklJ0e9+97vA/RYAACBo+b3OiBl8vU8ZAADUH7WyzggAAECgEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUDc0uINi5XNKnn0oFBVJMjDRokGS1ml0VAADBgzByHjIzpalTpe+++6ktLk564QVp1Cjz6gIAIJhwmaaGMjOl0aO9g4gkHTjgbs/MNKcuAACCTY3CyMKFCxUfH6/w8HAlJiZq27Zt1fY/cuSIJk+erJiYGNlsNl1yySVat25djQquD1wu94iIYVR+rqJt2jR3PwAAUD2/w8iqVauUmpqq2bNna8eOHUpISFBycrIOHjxYZf+ysjJdddVV2r9/v1avXq1du3ZpyZIlatu27XkXb5ZPP608IvJzhiHl57v7AQCA6vk9Z+S5557TpEmTNGHCBEnS4sWL9d5772np0qWaOXNmpf5Lly7Vjz/+qL///e9q1KiRJCk+Pv78qjZZQUFg+wEAcCHza2SkrKxM27dvV1JS0k8HaNBASUlJ2rp1a5X7vP322xowYIAmT56sqKgode/eXU8++aRc1VzDKC0tldPp9Nrqk5iYwPYDAOBC5lcYOXz4sFwul6Kiorzao6KiVFhYWOU++/bt0+rVq+VyubRu3TrNmjVLzz77rJ544omzvk5GRobsdrtnczgc/pRZ6wYNct81Y7FU/bzFIjkc7n4AAKB6tX43TXl5udq0aaOXXnpJffr00ZgxY/TII49o8eLFZ90nLS1NxcXFni0/P7+2y/SL1eq+fVeqHEgqHs+fz3ojAAD4wq8w0qpVK1mtVhUVFXm1FxUVKTo6usp9YmJidMkll8j6s0/mrl27qrCwUGVlZVXuY7PZFBER4bXVN6NGSatXS2fOw42Lc7ezzggAAL7xK4yEhYWpT58+ysrK8rSVl5crKytLAwYMqHKfgQMHas+ePSovL/e0/ec//1FMTIzCwsJqWHb9MGqUtH+/tHGjtGKF+2duLkEEAAB/+H2ZJjU1VUuWLNFf//pX7dy5U/fcc49KSko8d9eMGzdOaWlpnv733HOPfvzxR02dOlX/+c9/9N577+nJJ5/U5MmTA/dbmMhqla68UrrpJvdPLs0AAOAfv2/tHTNmjA4dOqT09HQVFhaqV69eWr9+vWdSa15enho0+CnjOBwOffDBB3rggQfUs2dPtW3bVlOnTtWMGTMC91sAAICgZTGMqtYRrV+cTqfsdruKi4vr5fwRAABQma+f33w3DQAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVDUKIwsXLlR8fLzCw8OVmJiobdu2+bTfa6+9JovFopEjR9bkZQEAQAjyO4ysWrVKqampmj17tnbs2KGEhAQlJyfr4MGD1e63f/9+TZ8+XYMGDapxsQAAIPT4HUaee+45TZo0SRMmTNBll12mxYsXq0mTJlq6dOlZ93G5XLr55ps1Z84cXXzxxedVcKhyuaTsbGnlSvdPl8vsigAAqBt+hZGysjJt375dSUlJPx2gQQMlJSVp69atZ91v7ty5atOmjSZOnOjT65SWlsrpdHptoSwzU4qPl4YMkcaOdf+Mj3e3AwAQ6vwKI4cPH5bL5VJUVJRXe1RUlAoLC6vcZ/PmzfrLX/6iJUuW+Pw6GRkZstvtns3hcPhTZlDJzJRGj5a++867/cABdzuBBAAQ6mr1bpqjR4/q1ltv1ZIlS9SqVSuf90tLS1NxcbFny8/Pr8UqzeNySVOnSoZR+bmKtmnTuGQDAAhtDf3p3KpVK1mtVhUVFXm1FxUVKTo6ulL/vXv3av/+/UpJSfG0lZeXu1+4YUPt2rVLHTt2rLSfzWaTzWbzp7Sg9OmnlUdEfs4wpPx8d78rr6yzsgAAqFN+jYyEhYWpT58+ysrK8rSVl5crKytLAwYMqNT/0ksv1VdffaWcnBzP9utf/1pDhgxRTk5OSF9+8UVBQWD7AQAQjPwaGZGk1NRUjR8/Xn379lX//v01f/58lZSUaMKECZKkcePGqW3btsrIyFB4eLi6d+/utX9kZKQkVWq/EMXEBLYfAADByO8wMmbMGB06dEjp6ekqLCxUr169tH79es+k1ry8PDVowMKuvhg0SIqLc09WrWreiMXifp6lWQAAocxiGFV9DNYvTqdTdrtdxcXFioiIMLucgKq4m0byDiQWi/vn6tXSqFF1XxcAAOfL189vhjBMNmqUO3C0bevdHhdHEAEAXBj8vkyDwBs1Shoxwn3XTEGBe47IoEGS1Wp2ZQAA1D7CSD1htXL7LgDgwsRlGgAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAU3FrbwhyuVizBAAQPAgjISYzU5o6Vfruu5/a4uKkF15gNVcAQP3EZZoQUvE9Nz8PIpL7i/hGj3Y/DwBAfUMYCREul3tEpKqvPaxomzbN3Q8AgPqEMBIiPv208ojIzxmGlJ/v7gcAQH1CGAkRBQWB7QcAQF0hjISImJjA9gMAoK4QRkLEoEHuu2Yslqqft1gkh8PdDwCA+oQwEiKsVvftu1LlQFLxeP581hsBANQ/hJEQMmqUtHq11Latd3tcnLuddUYAAPURi56FmFGjpBEjWIEVABA8CCMhyGqVrrzy/I/DsvIAgLpAGEGVWFYeAFBXmDOCSlhWHgBQlwgj8MKy8gCAukYYgReWlQcA1DXCCLywrDwAoK4RRuCFZeUBAHWNu2ngpWJZ+QMHqp43YrG4n/dnWXluEQYAVIeREXgJ9LLymZlSfLw0ZIg0dqz7Z3w8d+QAAH5CGEElgVpWnluEAQC+sBhGVYPx9YvT6ZTdbldxcbEiIiLMLueCcT6XV1wu9wjI2e7Mqbjck5vLJRsACFW+fn7XaGRk4cKFio+PV3h4uBITE7Vt27az9l2yZIkGDRqk5s2bq3nz5kpKSqq2P+qPimXlb7rJ/dOf0FAbtwi7XFJ2trRypfsna50AQGjwO4ysWrVKqampmj17tnbs2KGEhAQlJyfr4MGDVfbPzs7WTTfdpI0bN2rr1q1yOBy6+uqrdeDAgfMuHvVXoG8RZu4JAIQuvy/TJCYmql+/flqwYIEkqby8XA6HQ/fff79mzpx5zv1dLpeaN2+uBQsWaNy4cT69Jpdpgk92tjswnMvGjef+Ur+KuSdnvlMrJtT6M48FAFB3auUyTVlZmbZv366kpKSfDtCggZKSkrR161afjnH8+HGdOnVKLVq0OGuf0tJSOZ1Orw3BpeIW4TPvyKlgsUgOx7lvEWZ5egAIfX6FkcOHD8vlcikqKsqrPSoqSoWFhT4dY8aMGYqNjfUKNGfKyMiQ3W73bA6Hw58yUQ8E6hZh5p4AQOir01t7n3rqKb322mtas2aNwsPDz9ovLS1NxcXFni0/P78Oq0SgBOIWYeaeAEDo82sF1latWslqtaqoqMirvaioSNHR0dXuO2/ePD311FP66KOP1LNnz2r72mw22Ww2f0pDPTVqlDRiRM1vEQ7k8vRnm3tSse4Jc08AwBx+jYyEhYWpT58+ysrK8rSVl5crKytLAwYMOOt+Tz/9tB5//HGtX79effv2rXm1CErnc4twfZ57wuUeAAgMvy/TpKamasmSJfrrX/+qnTt36p577lFJSYkmTJggSRo3bpzS0tI8/X//+99r1qxZWrp0qeLj41VYWKjCwkIdO3YscL8FQlZ9nXvC5R4ACBy/w8iYMWM0b948paenq1evXsrJydH69es9k1rz8vJU8LML+H/84x9VVlam0aNHKyYmxrPNmzcvcL8FQlp9m3sS6GXuGWEBcKFjOXgEjfNZnj5Q654Eepn7zEz35aOfHy8uzj0axPwVAMHO189vwgguCBUh4sCBqueN+Boi6vNibucT1gCgNtTqd9MAwSZQc08Cdbkn0BNqmcMCIJgRRnDBCMTck0DdahzICbXMYQEQ7PxaZwQIdue77knFrcbnutxzrluN62qExWJxj7CMGMEcFgD1FyMjuOCcz7ongbrcwwgLAPyEMAL4KRCXewK1mBtzWACEAsIIUAOjRkn797vvmlmxwv0zN9f3SxmMsPiOERYg9BFGgBo6n8s9EiMsvgjkCAuhBqi/CCOAiRhhObtAjrBw2Qio3wgjgMkYYakskCMsXDYC6j/CCBACGGGpGpeNgOBAGAFCBCMslV0Il40INQgFhBEAHqE2whLql40INQgVhBEAXkJphCWULxsRahBKCCMAAq6+jLCE6mUjQg1CDWEEQK2oDyMsoXrZiFDju0CFGsJRLTOCQHFxsSHJKC4uNrsUAHXs9GnD2LjRMFascP88fdr/Y7z5pmHExRmG+yPWvTkc7nZfa4iLMwyLxfsYFZvF4j7euWrbuLHq/c/cNm6s/jgrVvh2nBUr6qaeivNztv19PT+G4f5vUtV5tljcm6//zSqOdWZdcXH+HSOQxzGMwLyfg4mvn9+EEQAXhPP9EKj4kDzzg9KfD0lCjW/npz6FmvoYjgwjcKGmtsMRYQQAAux8R1gqjkGoqd16AhVq6mM4qjhWfRvxORtfP7+ZMwIAPjrfibkVx6gvc2Hq211L9W1OTSjPzQn0ysTnizACAH4434m5EqHmbOpbqKlv4ShQoSbQKxMHAmEEAExAqKmsvoWa+haO6tuITyARRgAgiBFqKgtUqKlv4ai+jfgEEmEEAECoqcXj1LdQE6jjBJLFMKq6alS/OJ1O2e12FRcXKyIiwuxyAAC1zOVyXyYoKHB/KA4a5H9Aysx0z434+SUJh8MdIPwJSIE4TsWEUcl7rkZFQPElaLlc7sXfDhyoer6HxeIOPbm51Z+rQB3HF75+fhNGAAAhKxChJlDHqS+hJpDHORfCCAAA9Ux9CTWBPE51CCMAAISo+jTiUx1fP78bBu4lAQBAXaiYcFxfjnO+uJsGAACYijACAABMVaMwsnDhQsXHxys8PFyJiYnatm1btf3feOMNXXrppQoPD1ePHj20bt26GhULAABCj99hZNWqVUpNTdXs2bO1Y8cOJSQkKDk5WQcPHqyy/9///nfddNNNmjhxor744guNHDlSI0eO1Ndff33exQMAgODn9900iYmJ6tevnxYsWCBJKi8vl8Ph0P3336+ZM2dW6j9mzBiVlJTo3Xff9bT94he/UK9evbR48WKfXpO7aQAACD6+fn77NTJSVlam7du3Kykp6acDNGigpKQkbd26tcp9tm7d6tVfkpKTk8/aX5JKS0vldDq9NgAAEJr8CiOHDx+Wy+VSVFSUV3tUVJQKCwur3KewsNCv/pKUkZEhu93u2RwOhz9lAgCAIFIv76ZJS0tTcXGxZ8vPzze7JAAAUEv8WvSsVatWslqtKioq8movKipSdHR0lftER0f71V+SbDabbDabP6UBAIAg5VcYCQsLU58+fZSVlaWRI0dKck9gzcrK0n333VflPgMGDFBWVpamTZvmaduwYYMGDBjg8+tWzLFl7ggAAMGj4nP7nPfKGH567bXXDJvNZixfvtz497//bdx5551GZGSkUVhYaBiGYdx6663GzJkzPf23bNliNGzY0Jg3b56xc+dOY/bs2UajRo2Mr776yufXzM/PNySxsbGxsbGxBeGWn59f7ee8399NM2bMGB06dEjp6ekqLCxUr169tH79es8k1by8PDVo8NNUlMsvv1wrVqzQo48+qocfflidO3fW2rVr1b17d59fMzY2Vvn5+WrWrJksFoucTqccDofy8/O51beWca7rBue5bnCe6wbnuW4Ew3k2DENHjx5VbGxstf2C4lt7z8S6I3WHc103OM91g/NcNzjPdSOUznO9vJsGAABcOAgjAADAVEEZRmw2m2bPns3tv3WAc103OM91g/NcNzjPdSOUznNQzhkBAAChIyhHRgAAQOggjAAAAFMRRgAAgKkIIwAAwFSEEQAAYKqgDCMLFy5UfHy8wsPDlZiYqG3btpldUkh57LHHZLFYvLZLL73U7LKC3qZNm5SSkqLY2FhZLBatXbvW63nDMJSenq6YmBg1btxYSUlJ2r17tznFBrlznevbbrut0nt82LBh5hQbpDIyMtSvXz81a9ZMbdq00ciRI7Vr1y6vPidPntTkyZPVsmVLNW3aVNdff32lb3HHuflyrq+88spK7+m7777bpIr9F3RhZNWqVUpNTdXs2bO1Y8cOJSQkKDk5WQcPHjS7tJDSrVs3FRQUeLbNmzebXVLQKykpUUJCghYuXFjl808//bT+8Ic/aPHixfrss8900UUXKTk5WSdPnqzjSoPfuc61JA0bNszrPb5y5co6rDD4ffLJJ5o8ebL+8Y9/aMOGDTp16pSuvvpqlZSUePo88MADeuedd/TGG2/ok08+0ffff69Ro0aZWHVw8uVcS9KkSZO83tNPP/20SRXXgL/f2mu2/v37G5MnT/Y8drlcRmxsrJGRkWFiVaFl9uzZRkJCgtllhDRJxpo1azyPy8vLjejoaOOZZ57xtB05csSw2WzGypUrTagwdJx5rg3DMMaPH2+MGDHClHpC1cGDBw1JxieffGIYhvv926hRI+ONN97w9Nm5c6chydi6datZZYaEM8+1YRjGFVdcYUydOtW8os5TUI2MlJWVafv27UpKSvK0NWjQQElJSdq6dauJlYWe3bt3KzY2VhdffLFuvvlm5eXlmV1SSMvNzVVhYaHXe9tutysxMZH3di3Jzs5WmzZt1KVLF91zzz364YcfzC4pqBUXF0uSWrRoIUnavn27Tp065fWevvTSS9WuXTve0+fpzHNd4dVXX1WrVq3UvXt3paWl6fjx42aUVyMNzS7AH4cPH5bL5VJUVJRXe1RUlL755huTqgo9iYmJWr58ubp06aKCggLNmTNHgwYN0tdff61mzZqZXV5IKiwslKQq39sVzyFwhg0bplGjRqlDhw7au3evHn74YQ0fPlxbt26V1Wo1u7ygU15ermnTpmngwIHq3r27JPd7OiwsTJGRkV59eU+fn6rOtSSNHTtW7du3V2xsrL788kvNmDFDu3btUmZmponV+i6owgjqxvDhwz1/7tmzpxITE9W+fXu9/vrrmjhxoomVAYFx4403ev7co0cP9ezZUx07dlR2draGDh1qYmXBafLkyfr666+ZW1YHznau77zzTs+fe/TooZiYGA0dOlR79+5Vx44d67pMvwXVZZpWrVrJarVWmo1dVFSk6Ohok6oKfZGRkbrkkku0Z88es0sJWRXvX97b5rj44ovVqlUr3uM1cN999+ndd9/Vxo0bFRcX52mPjo5WWVmZjhw54tWf93TNne1cVyUxMVGSguY9HVRhJCwsTH369FFWVpanrby8XFlZWRowYICJlYW2Y8eOae/evYqJiTG7lJDVoUMHRUdHe723nU6nPvvsM97bdeC7777TDz/8wHvcD4Zh6L777tOaNWv08ccfq0OHDl7P9+nTR40aNfJ6T+/atUt5eXm8p/10rnNdlZycHEkKmvd00F2mSU1N1fjx49W3b1/1799f8+fPV0lJiSZMmGB2aSFj+vTpSklJUfv27fX9999r9uzZslqtuummm8wuLagdO3bM618pubm5ysnJUYsWLdSuXTtNmzZNTzzxhDp37qwOHTpo1qxZio2N1ciRI80rOkhVd65btGihOXPm6Prrr1d0dLT27t2r3/72t+rUqZOSk5NNrDq4TJ48WStWrNBbb72lZs2aeeaB2O12NW7cWHa7XRMnTlRqaqpatGihiIgI3X///RowYIB+8YtfmFx9cDnXud67d69WrFiha665Ri1bttSXX36pBx54QIMHD1bPnj1Nrt5HZt/OUxMvvvii0a5dOyMsLMzo37+/8Y9//MPskkLKmDFjjJiYGCMsLMxo27atMWbMGGPPnj1mlxX0Nm7caEiqtI0fP94wDPftvbNmzTKioqIMm81mDB061Ni1a5e5RQep6s718ePHjauvvtpo3bq10ahRI6N9+/bGpEmTjMLCQrPLDipVnV9JxrJlyzx9Tpw4Ydx7771G8+bNjSZNmhjXXXedUVBQYF7RQepc5zovL88YPHiw0aJFC8NmsxmdOnUyHnroIaO4uNjcwv1gMQzDqMvwAwAA8HNBNWcEAACEHsIIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJjq/wOuqf3bg5NtuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [1731494, 1796870, 1669408, 1256227, 1, 18920]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.LongTensor(sentence_word_idxs).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.5010e-08, 9.1991e-06, 1.3806e-04, 4.0274e-07, 3.1721e-05, 7.5362e-06,\n",
       "        9.9927e-01, 5.8261e-07, 1.7679e-08, 9.6882e-06, 2.7822e-07, 7.6344e-07,\n",
       "        4.1881e-08, 4.6079e-07, 1.8408e-06, 4.2224e-06, 5.5055e-05, 8.1020e-08,\n",
       "        1.1245e-07, 8.8158e-07, 6.4205e-06, 2.1828e-06, 4.5968e-04],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(word, 1) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([1544992, 1565068, 1731494,  469497,  632240,  900752, 1075419, 1751214,\n",
      "        1695414,  225306,  459199, 1642097, 1613783,  900752, 1731494, 1434430,\n",
      "          18920,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model1.state_dict(), 'model.pt')\n",
    "# torch.cuda.empty_cache()\n",
    "# model1.load_state_dict(torch.load('model.pt'))\n",
    "# model1.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-5.5129,  0.4265, -0.5284,  ..., -2.0908, -5.9108,  1.9737],\n",
      "        [-6.9847, -4.4360, -1.6372,  ..., -4.6631,  1.3284,  2.0589],\n",
      "        [-8.8295, -1.8219, -1.2824,  ..., -3.6861, -4.2177,  1.2335],\n",
      "        ...,\n",
      "        [-6.2952, -2.3478, -1.7486,  ..., -1.9785, -4.9048,  3.9807],\n",
      "        [-5.7952, -1.8021, -1.3064,  ..., -1.8298, -4.3204,  3.1336],\n",
      "        [-5.0518, -1.5886, -1.2721,  ..., -1.5438, -4.1281,  2.3654]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025198938992043"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
