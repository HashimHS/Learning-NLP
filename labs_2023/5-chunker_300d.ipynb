{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fec3558b930>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300 #50\n",
    "LSTM_HIDDEN_DIM = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_file = 'corpus/glove.6B.100d.txt'\n",
    "embedding_file = 'corpus/glove.42B.300d.txt'\n",
    "# embedding_file = 'corpus/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 1917494'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1/2/2008',\n",
       " '1/2/2009',\n",
       " '1/2/2010',\n",
       " '1/2/2011',\n",
       " '1/2/2012',\n",
       " '1/2/2013',\n",
       " '1/2/3',\n",
       " '1/2/4',\n",
       " '1/2/5',\n",
       " '1/20']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73117 , -0.44407 ,  0.22863 ,  0.32582 , -0.069017,  0.29342 ,\n",
       "       -1.6415  , -0.23372 ,  0.11325 , -0.80541 ,  0.58405 ,  0.16712 ,\n",
       "       -0.89039 ,  0.37771 , -0.24962 ,  0.40288 , -0.10095 ,  0.064693,\n",
       "       -0.18085 ,  0.51575 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_similarity(d1, d2):\n",
    "    return np.dot(d1, d2) / (np.sqrt(np.dot(d1, d1)) * np.sqrt(np.dot(d2, d2)))\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    distances = []\n",
    "    for word in embeddings:\n",
    "        distances.append((word, cosine_similarity(embeddings[target_word], embeddings[word])))\n",
    "    distances.sort(key=lambda x: x[1], reverse=True)\n",
    "    return list(map(lambda x: x[0], distances[0:count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'europe',\n",
       " 'paris',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'spain',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'switzerland',\n",
       " 'luxembourg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'germany',\n",
       " 'estonia',\n",
       " 'stockholm',\n",
       " 'switzerland',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            X.append([word[key_x].lower() for word in sentence])\n",
    "        else:\n",
    "            X.append([word[key_x] for word in sentence])\n",
    "        Y.append([word[key_y] for word in sentence])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "chunks = []\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words.append(word['form'].lower())\n",
    "        chunks.append(word['chunk'])\n",
    "words = sorted(list(set(words)))\n",
    "chunks = sorted(list(set(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(words + embedded_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 1918351\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1913-17',\n",
       " '1913-1914',\n",
       " '1913-1914.',\n",
       " '1913-1915',\n",
       " '1913-1916',\n",
       " '1913-1917',\n",
       " '1913-1918',\n",
       " '1913-1919',\n",
       " '1913-1920',\n",
       " '1913-1921']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = dict(enumerate(vocabulary_words, start=2))\n",
    "idx2chunk = dict(enumerate(chunks, start=1))\n",
    "word2idx = {v:k for k,v in idx2word.items()}\n",
    "chunk2idx = {v:k for k,v in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!!!!!!', 7), ('!!!!!!!', 8), ('!!!!!!!!', 9), ('!!!!!!!!!', 10), ('!!!!!!!!!!', 11), ('!!!!!!!!!!!', 12), ('!!!!!!!!!!!!', 13), ('!!!!!!!!!!!!!', 14), ('!!!!!!!!!!!!!!', 15), ('!!!!!!!!!!!!!!!', 16), ('!!!!!!!!!!!!!!!!', 17), ('!!!!!!!!!!!!!!!!!', 18), ('!!!!!!!!!!!!!!!!!!', 19), ('!!!!!!!!!!!!!!!!!!!', 20), ('!!!!!!!!!!!!!!!!!!!!', 21), ('!!!!!!!!!!!!!!!!!!!!!', 22), ('!!!!!!!!!!!!!!!!!!!!!!', 23), ('!!!!!!!!!!!!!!!!!!!!!!!', 24), ('!!!!!!!!!!!!!!!!!!!!!!!!', 25), ('!!!!!!!!!!!!!!!!!!!!!!!!!', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918353, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"women's-rights\",\n",
       " 'woodmac',\n",
       " 'worker-compensation',\n",
       " 'working-girl',\n",
       " 'world-commerce',\n",
       " \"y'all\",\n",
       " 'year-before',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48524001,  0.039558  , -0.046947  , -0.056083  ,  0.84688002,\n",
       "       -0.095761  , -2.54049993,  0.39072999, -0.097248  ,  0.21303999])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00540048,  0.03457306, -0.01296801,  0.02510228,  0.00136785,\n",
       "       -0.03044032,  0.02263095,  0.02768296, -0.01973514, -0.02316351])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[704294, 1048244, 1731494, 1455426, 1071851, 1863829, 860507, 1751214, 1710857, 499157, 1609325, 785044, 1040147, 1762233, 883861, 900752, 1599158, 9515, 806382, 900752, 1521897, 1754377, 9515, 868101, 1751214, 1617369, 443770, 1687079, 1047894, 913392, 1099957, 494188, 530486, 7570, 1312851, 759020, 18920], [660791, 1357047, 1731494, 858787, 1325916, 1157370, 7570, 1529811, 698555, 1751214, 443770, 888765, 1274105, 1445191, 987527, 997085, 1751214, 1465292, 443770, 909720, 1048244, 1673095, 1382220, 1731494, 1403053, 1853609, 18920], [621821, 493351, 1514116, 1794062, 1695484, 900752, 1673095, 987527, 563339, 845992, 623644, 1731494, 660791, 7570, 868194, 1751214, 498575, 503890, 1319837, 1445191, 1237106, 1048244, 1007689, 1217626, 1020477, 1655621, 1154387, 1742442, 18920]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 660791, 1357047, 1731494,  858787, 1325916, 1157370,    7570, 1529811,\n",
       "         698555, 1751214,  443770,  888765, 1274105, 1445191,  987527,  997085,\n",
       "        1751214, 1465292,  443770,  909720, 1048244, 1673095, 1382220, 1731494,\n",
       "        1403053, 1853609,   18920,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,       0,       0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, \n",
    "                                                       freeze=False, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, \n",
    "                            dropout=0.2, batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hashim/miniconda3/envs/lt/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(1918353, 300, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(300, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/559 [01:25<55:33,  6.12s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hashim/edan20/labs_2023/5-chunker.ipynb Cell 116\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hashim/edan20/labs_2023/5-chunker.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hashim/edan20/labs_2023/5-chunker.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hashim/edan20/labs_2023/5-chunker.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hashim/edan20/labs_2023/5-chunker.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hashim/edan20/labs_2023/5-chunker.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(X_train), \u001b[39m256\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model1.to(device)\n",
    "for epoch in range(15):\n",
    "    start_time = timer()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)        \n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_train), 256):\n",
    "            x = X_train[i:i+256,:].to(device)\n",
    "            y = Y_train[i:i+256].to(device)\n",
    "            train_accuracy += torch.sum(torch.mul(torch.argmax(model1(x), dim=-1) == y, y > 0))\n",
    "    # train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy.item()/torch.sum(Y_train > 0)]\n",
    "    history['loss'] += [train_loss/batch_cnt]\n",
    "    end_time = timer()\n",
    "    print((f\"Epoch: {epoch}, Train loss: {history['loss'][-1].item():.3f}, Train acc.: {history['accuracy'][-1].item():.3f},  Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9896)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.LongTensor(sentence_word_idxs).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8946e-10, 2.3316e-07, 2.4024e-08, 2.2046e-13, 1.4504e-06, 9.0489e-08,\n",
       "        9.9984e-01, 9.9312e-10, 7.3756e-13, 2.0409e-08, 1.7903e-10, 6.5337e-11,\n",
       "        6.8341e-11, 2.9573e-10, 7.4839e-11, 1.4618e-10, 2.4035e-05, 8.6507e-11,\n",
       "        3.1419e-12, 5.0517e-10, 6.7897e-11, 9.5257e-11, 1.3264e-04],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(word, 1) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (lstm): LSTM(100, 192, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=384, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model1.state_dict(), 'model.pt')\n",
    "# torch.cuda.empty_cache()\n",
    "# model1.load_state_dict(torch.load('model.pt'))\n",
    "model1.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[ -9.1381,  -6.2476,  -5.9447,  ...,  -7.1595,  -8.6915,   0.5529],\n",
      "        [ -9.2804,  -5.6719,  -4.6651,  ...,  -5.4780,   1.1012,   0.0621],\n",
      "        [-10.6075,  -5.3978,  -4.9779,  ...,  -6.2755,  -9.2277,   0.4150],\n",
      "        ...,\n",
      "        [ -6.2930,  -2.9178,  -1.9216,  ...,  -7.3043,  -9.8744,   1.7307],\n",
      "        [ -7.1842,  -3.1360,  -0.5229,  ...,  -9.0162, -12.2198,   0.1135],\n",
      "        [ -6.1331,  -2.0188,  -0.2223,  ...,  -9.6228, -10.9966,   0.9630]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898664181422802"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
